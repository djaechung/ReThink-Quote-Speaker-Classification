{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "5652b410",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4c8678a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lauranixon/opt/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3437: DtypeWarning: Columns (9,10,24) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "articledf = pd.read_json(\"../novetta_files/GNI88-json.json\")\n",
    "\n",
    "quotedf = pd.read_csv(\"../novetta_files/quote_data/GNI88.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "455c683f",
   "metadata": {},
   "source": [
    "### Clean full texts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f6975ff",
   "metadata": {},
   "source": [
    "##### Regex patterns to remove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6bf3ebb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Patterns at start of article\n",
    "allarticle_header_regex = \"Media: .*\\nAuthor: (?:.*\\n){1,10}Date: .*\\n\\n\"\n",
    "allarticle_header_regex_byline = \"Media: .*\\r\\nByline: (?:.*\\r\\n){1,10}Date: .*\\r\\n\\r\\n\"\n",
    "politico_share_regex = '.*\\n{1,20}Follow Us\\n'\n",
    "politico_date_regex = '^.*\\nBy.*\\n\\d\\d/\\d\\d/\\d\\d\\d\\d \\d\\d:\\d\\d (?:AM|PM) EDT'\n",
    "\n",
    "#Patterns at end of article\n",
    "dow_regex = 'License this article from Dow Jones Reprint Service'\n",
    "\n",
    "#Patterns in article\n",
    "#search for line with only all caps and punctuation\n",
    "fox_bold_regex = \"\\n[A-Z ',.-]+\\n\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05da938a",
   "metadata": {},
   "source": [
    "##### Find regex patterns and remove them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "63614675",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_patterns = [allarticle_header_regex, allarticle_header_regex_byline, dow_regex, politico_date_regex]\n",
    "\n",
    "articledf['Body'] = articledf['Body'].replace(to_replace=\"|\".join(remove_patterns), value=\"\", regex=True)\n",
    "\n",
    "\n",
    "#Remove ALL CAPS lines in Fox news articles\n",
    "articledf['Body'] = np.where(articledf['Media Name'] == 'Fox News', \n",
    "                           articledf['Body'].replace(to_replace=fox_bold_regex, value=\"\", regex=True),\n",
    "                           articledf['Body'])\n",
    "\n",
    "#Remove irrelevant lines at start of Politico \"playbook\" articles\n",
    "articledf['Body'] = np.where(articledf['Media Name'] == 'Politico', \n",
    "                           articledf['Body'].replace(to_replace=politico_share_regex, value=\"\", regex=True),\n",
    "                           articledf['Body'])             "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1690cfa9",
   "metadata": {},
   "source": [
    "### Map full text to labelled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "e9e678b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a dictionary of article ids matched with their respective full texts\n",
    "id_article_dict = pd.Series(articledf.Body.values,index=articledf[\"Article ID\"]).to_dict()\n",
    "\n",
    "# Mapping the id-to-fulltext dictionary to create a Full Text column in the labelled df\n",
    "quotedf['fulltext']= quotedf['Article ID'].map(id_article_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d16fb9a",
   "metadata": {},
   "source": [
    "### Remove irrelevant articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "0cdc120b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove all Spanish articles\n",
    "spanish_outlets = ['El Nuevo Herald', 'El Diario La Prensa', 'Univision', 'AP Spanish Worldstream']\n",
    "quotedf = quotedf[-quotedf[\"Media Name\"].isin(spanish_outlets)]\n",
    "\n",
    "#Filter out Bloomberg show transcripts\n",
    "quotedf = quotedf[-((quotedf[\"Media Name\"]=='Bloomberg') & (quotedf.Headline.str.contains('Full Show')))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cfa53ec",
   "metadata": {},
   "source": [
    "### Clean Source Name column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "83394c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop \"OLD\" labels from name strings\n",
    "quotedf[\"source_name_cleaned\"] = quotedf[\"Source Name\"].str.split(\" OLD\", expand =True)[0]\n",
    "\n",
    "#Drop anything in parentheses\n",
    "quotedf[\"source_name_cleaned\"] = quotedf[\"source_name_cleaned\"].str.split(r\" \\(.*\\)\", expand =True)[0]\n",
    "\n",
    "#Strip trailing commas, and leading and trailing whitespace, then check for trailing commas again\n",
    "quotedf[\"source_name_cleaned\"] = quotedf[\"source_name_cleaned\"].str.rstrip(\",\").str.strip().str.rstrip(\",\")#.str.strip(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc40f4ae",
   "metadata": {},
   "source": [
    "### Export to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "c901e1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "quotedf.to_csv(\"GNI88_cleaned_data.csv\", index=False, quoting=csv.QUOTE_NONNUMERIC)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
