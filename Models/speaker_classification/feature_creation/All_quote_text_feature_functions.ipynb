{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YujiaoZhao/Carla_Pull/blob/main/AllFeatures.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n1xQcInrj77H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eac24981-8a3d-494b-ea82-3539e10850f4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: vaderSentiment in /usr/local/lib/python3.7/dist-packages (3.3.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from vaderSentiment) (2.23.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->vaderSentiment) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->vaderSentiment) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->vaderSentiment) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->vaderSentiment) (2022.9.24)\n"
          ]
        }
      ],
      "source": [
        "#importing in libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import regex as re\n",
        "import string\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import Counter\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "!pip install vaderSentiment\n",
        "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
        "from scipy import stats as st\n",
        "import json\n",
        "import re\n",
        "from nltk.tokenize.regexp import WhitespaceTokenizer\n",
        "from nltk import tokenize\n",
        "from google.colab import drive"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Function for Count of Numbers\n",
        "\n",
        "This function will return a list with the count of numerical values for each String in QText."
      ],
      "metadata": {
        "id": "Ihkk7PKRluEC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def number_count(texts):\n",
        "    \"\"\" Input: Series of Strings\n",
        "        Output: List with number of numerical values in the text\n",
        "        The function accounts for the fact that there is \n",
        "        sometimes commas and decimals in numbers\"\"\"\n",
        "    number_counts = []\n",
        "    for i in texts:\n",
        "        text_wo_punct = i.replace(\",\", \"\").replace(\".\", \"\")\n",
        "        number_counts.append(len(re.findall(\"[0-9]+\", text_wo_punct)))\n",
        "    return number_counts"
      ],
      "metadata": {
        "id": "cSp9dXrDlfup"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Function for Count of Numbers and Number Words\n",
        "\n",
        "Number words accounts for written out numbers that include hundred, thousand, million, billion, trillion, or dozen."
      ],
      "metadata": {
        "id": "s6dyr5UImCkY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def number_and_numwords_count(texts):\n",
        "    \"\"\" Input: Series of strings \n",
        "        Output: List of the counts of numerical values and \n",
        "        number words in each String in the Series.\n",
        "        The function accounts for the fact that there is \n",
        "        sometimes commas and decimals in numbers \"\"\"\n",
        "    number_counts = []\n",
        "    for i in texts:\n",
        "        \n",
        "        text_clean = i.replace(\",\", \"\").replace(\".\", \"\").lower()\n",
        "        num_words = len(re.findall(r\"\\bhundreds?|thousands?|millions?|billions?|trillions?|dozens?\\b\", text_clean))\n",
        "        nums = len(re.findall(\"[0-9]+\", text_clean))\n",
        "        number_counts.append(num_words + nums)\n",
        "    \n",
        "    \n",
        "    return number_counts"
      ],
      "metadata": {
        "id": "ntjpG0ZFmVPb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Has Numerical Value Function\n",
        "This function will take in a the \"QText\" column and return an array with 1 for Quotes which contain any type of numerical value (number or number word) and 0 otherwise."
      ],
      "metadata": {
        "id": "v97qYoKBmac3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def has_number(texts):\n",
        "    \"\"\" Input: Series of strings (QText column)\n",
        "        Output: List of 1s and 0s. 1 means that the \n",
        "        string contained a number or number word.\n",
        "        The function accounts for the fact that there is \n",
        "        sometimes commas and decimals in numbers \"\"\"\n",
        "    number_counts = []\n",
        "    for i in texts:\n",
        "        \n",
        "        text_clean = i.replace(\",\", \"\").replace(\".\", \"\").lower()\n",
        "        num_words = len(re.findall(r\"\\bhundreds?\\b|\\bthousands?\\b|\\bmillions?\\b|\\bbillions?\\b|\\btrillions?\\b|\\bdozens?\\b\", text_clean))\n",
        "        nums = len(re.findall(\"[0-9]+\", text_clean))\n",
        "        number_counts.append(num_words + nums)\n",
        "    has_num = []\n",
        "    for x in number_counts:\n",
        "        if x > 0:\n",
        "            has_num.append(1)\n",
        "        else:\n",
        "            has_num.append(0)\n",
        "            \n",
        "    return has_num"
      ],
      "metadata": {
        "id": "8QfLOX2qmWD5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Function for Count of Group Words\n",
        "When I say \"group words,\" I am referring to the words: us, our, ours, and we."
      ],
      "metadata": {
        "id": "uoMYSmaimmCJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def group_wrd_count(texts):\n",
        "    \"\"\" Input: Series of strings (QText column)\n",
        "        Output: List of count of group words in \n",
        "        each string.\n",
        "        \"\"\"\n",
        "    word_counts = []\n",
        "    for text in texts:\n",
        "        text_lowercase = text.lower()\n",
        "        text_clean = re.sub(r\"[^\\w\\s]\", \" \",text_lowercase)\n",
        "        words_count = len(re.findall(r\"\\bus\\b|\\bours?\\b|\\bwe\\b\", text_clean)) \n",
        "        word_counts.append(words_count)\n",
        "    return word_counts\n"
      ],
      "metadata": {
        "id": "-kS6-9b4mlSH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Function for Frequency of Group Words"
      ],
      "metadata": {
        "id": "-yrQrOnQm_Ho"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def group_wrd_freq(texts):\n",
        "    \"\"\" Input: Series of strings (QText column)\n",
        "        Output: List of frequency of group words in \n",
        "        each string (# of \"group words\" / total # of words).\n",
        "        \"\"\"\n",
        "    word_counts = []\n",
        "    quote_lengths = []\n",
        "    \n",
        "    for text in texts:\n",
        "        text_lowercase = text.lower()\n",
        "        text_clean = re.sub(r\"[^\\w\\s]\", \" \",text_lowercase)\n",
        "        words_count = len(re.findall(r\"\\bus\\b|\\bours?\\b|\\bwe\\b\", text_clean)) \n",
        "        word_counts.append(words_count)\n",
        "        if type(text) == float:\n",
        "            quote_lengths.append(0)\n",
        "        else:\n",
        "            quote_lengths.append(len(text.split()))\n",
        "        \n",
        "    return list(np.array(word_counts) / np.array(quote_lengths))"
      ],
      "metadata": {
        "id": "T6AytFV5nBz1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Function for Has Group Word\n",
        "This function checks if there is at least one group word in each of a Series of Strings."
      ],
      "metadata": {
        "id": "Nu2RpobOnFqy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def has_group_word(texts):\n",
        "    \"\"\" Input: Series of strings (QText column)\n",
        "        Output: List of 1s and 0s. 1 means that the \n",
        "        string contained a group word.\n",
        "        \"\"\"\n",
        "    group_word_counts = []\n",
        "    for text in texts:\n",
        "        text_lowercase = text.lower()\n",
        "        text_clean = re.sub(r\"[^\\w\\s]\", \" \",text_lowercase)\n",
        "        words_count = len(re.findall(r\"\\bus\\b|\\bours?\\b|\\bwe\\b\", text_clean)) \n",
        "        group_word_counts.append(words_count)\n",
        "        \n",
        "    has_group_word = []\n",
        "    for count in group_word_counts:\n",
        "        if count > 0:\n",
        "            has_group_word.append(1)\n",
        "        else:\n",
        "            has_group_word.append(0)\n",
        "            \n",
        "    return has_group_word"
      ],
      "metadata": {
        "id": "Z_OAOO19oZA7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JDK879Q4okvk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sentiment Feature Function"
      ],
      "metadata": {
        "id": "xlllYcHR9MaP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vader = SentimentIntensityAnalyzer()\n",
        "\n",
        "def sentence_vader(string):\n",
        "    sentence_list = tokenize.sent_tokenize(string)\n",
        "    score_list = []\n",
        "    for sentence in sentence_list:\n",
        "        score = vader.polarity_scores(sentence)\n",
        "        score_list.append(score['compound'])\n",
        "    return np.mean(score_list)"
      ],
      "metadata": {
        "id": "in2jVTGL95n6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def vader_15(string):\n",
        "    split_string = string.split(\" \")\n",
        "    length = len(split_string)\n",
        "    sentence_list = []\n",
        "    for i in range(length//15):\n",
        "        sentence = \" \".join(split_string[i*15:(i+1)*15])\n",
        "        sentence_list.append(sentence)\n",
        "    if length % 15 != 0:\n",
        "        digit = length%15\n",
        "        remainder = \" \".join(split_string[-digit:])\n",
        "        sentence_list.append(remainder)\n",
        "    \n",
        "    score_list = []\n",
        "    for sentence in sentence_list:\n",
        "        score = vader.polarity_scores(sentence)\n",
        "        score_list.append(score['compound'])\n",
        "    return np.mean(score_list)"
      ],
      "metadata": {
        "id": "nWVjRobg9jPC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Subjectivity Feature Function"
      ],
      "metadata": {
        "id": "9ofv5juJ-BuF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Loading the MPQA Subjectivity Clues Lexicon (https://mpqa.cs.pitt.edu/lexicons/subj_lexicon/)\n",
        "drive.mount('/content/drive')\n",
        "file_path = 'drive/My Drive/mpqa_dict.json'\n",
        "mpqa_dict = json.load(open(file_path, \"r\"))\n",
        "\n",
        "def get_subjectivity(art_str, mpqa_dict):\n",
        "    subjectivity, adjectives, sub_adjectives = 0, 0, 0\n",
        "    words = re.sub(\"[^\\w]\", \" \",  art_str).split()\n",
        "    quote_len = len(words)\n",
        "    \n",
        "    for w in words:\n",
        "        if w in mpqa_dict:  \n",
        "            if mpqa_dict[w]['subj'] == 'weaksubj':\n",
        "                subjectivity += 0.1\n",
        "            if mpqa_dict[w]['subj'] == 'strongsubj':\n",
        "                subjectivity += 1\n",
        "            if mpqa_dict[w]['pos'] == 'adj' :\n",
        "                adjectives += 1\n",
        "                if mpqa_dict[w]['subj'] == 'weaksubj':\n",
        "                    sub_adjectives += 0.1\n",
        "                if mpqa_dict[w]['subj'] == 'strongsubj':\n",
        "                    sub_adjectives += 1\n",
        "    \n",
        "    subjectivity_final = subjectivity/quote_len*100\n",
        "    sub_adjectives_final = sub_adjectives/quote_len*100\n",
        "    \n",
        "    return subjectivity_final, sub_adjectives_final"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ITC2BSqW9jYg",
        "outputId": "7e9c7b76-cebd-435b-f168-af8af3a94d06"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Has Nuke Function"
      ],
      "metadata": {
        "id": "XHkp_AaNPw0_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Indicates if the word 'nuke' was used in the text using regex\n",
        "def has_nuke(text):\n",
        "    if type(text) == str:\n",
        "        return int(len(re.findall(\"(nukes?[^\\w])\", text)) > 0)\n",
        "    else:\n",
        "        return 0"
      ],
      "metadata": {
        "id": "aqMYPXwJMjqq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Count British Words Function"
      ],
      "metadata": {
        "id": "pRmF8YhjP3tf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Imports british to american word dictionary and function counts number of british words in the text\n",
        "import requests\n",
        "url =\"https://raw.githubusercontent.com/hyperreality/American-British-English-Translator/master/data/british_spellings.json\"\n",
        "british_to_american_dict = requests.get(url).json()\n",
        "british_words = list(british_to_american_dict.keys())\n",
        "remove_words = ['buses', 'disc', 'dialogue', 'gramme']\n",
        "british_words_edited = list(british_to_american_dict.keys())\n",
        "[british_words_edited.remove(w) for w in remove_words]\n",
        "\n",
        "def count_british_edited(text):\n",
        "    count = 0\n",
        "    if type(text) == str:\n",
        "        for i in british_words_edited:\n",
        "            count += text.count(i + \" \")\n",
        "            count += text.count(i + \".\")\n",
        "            count += text.count(i + \"?\")\n",
        "            count += text.count(i + \",\")\n",
        "            count += text.count(i + \"-\")\n",
        "            count += text.count(i + \":\")\n",
        "    return count"
      ],
      "metadata": {
        "id": "WlIq7jsRNa9E"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
