{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "feature_finding_updated.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "jHj54zQbwwqH"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import json\n",
        "import csv\n",
        "import regex as re\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JLahYh6TxIlc",
        "outputId": "9b8f0bb8-d2a5-4153-a43d-058ab5514445"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Setup"
      ],
      "metadata": {
        "id": "7Q57GoOZySVk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Establishing Dataframes"
      ],
      "metadata": {
        "id": "biKBpFlJyXgQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Reading a fixed version GNI88.csv (replaced one double quote with a single quote in line 369292) to a Pandas df\n",
        "qtes = pd.read_csv(\"/content/drive/MyDrive/data/GNI88_fixed.csv\")"
      ],
      "metadata": {
        "id": "WgYPvGuPxLC3"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reading gni88.json to a Pandas df\n",
        "arts = pd.read_json(\"/content/drive/MyDrive/data/gni88.json\", lines=True)"
      ],
      "metadata": {
        "id": "Qbk3K7H2x3Hg"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = qtes"
      ],
      "metadata": {
        "id": "zPFU4HKq-LJ0"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Speaker name cleaning"
      ],
      "metadata": {
        "id": "4x6Yyc0Iybyf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# credit: Lana\n",
        "def remove_prefix(text):\n",
        "    for prefix in prefixes:\n",
        "      if text.lower().startswith(prefix):\n",
        "        slicer = len(prefix)\n",
        "        return text[slicer:]\n",
        "    return text\n",
        "\n",
        "def remove_suffix(text):\n",
        "    for suffix in suffixes:\n",
        "      if text.endswith(suffix):\n",
        "        slicer = len(suffix)\n",
        "        return text[:-slicer]\n",
        "    return text\n",
        "\n",
        "\n",
        "def regex_trim(rx_list, column, df, replace_value=\"\"):\n",
        "    '''Takes a list of regex patterns, and joins the patterns with an OR (|) separator. \n",
        "    Searches the specified column/df for the pattern and replaces it with value specified (default value-nothing)'''\n",
        "    df[column] = df[column].replace(to_replace=\"|\".join(rx_list), value=replace_value, regex=True)\n",
        "    return df\n",
        "\n",
        "def remove_accents(txt):\n",
        "    \"\"\"Certain outlets (CTV News) do not use accented characters in person names.\n",
        "       Others (CBC News and Global news), always use accented characters in names.\n",
        "       To help normalize these names and get accurate counts of sources, we replace \n",
        "       accented characters with their regular English equivalents.\n",
        "       Example names that are normalized across different outlets using this method:\n",
        "        * François Legault <-> Francois Legault\n",
        "        * Valérie Plante <-> Valerie Plante\n",
        "        * Jean Chrétien <-> Jean Chretien \n",
        "    \"\"\"\n",
        "    txt = re.sub(\"[àáâãäå]\", 'a', txt)\n",
        "    txt = re.sub(\"[èéêë]\", 'e', txt)\n",
        "    txt = re.sub(\"[ìíîïı]\", 'i', txt)\n",
        "    txt = re.sub(\"[òóôõö]\", 'o', txt)\n",
        "    txt = re.sub(\"[ùúûü]\", 'u', txt)\n",
        "    txt = re.sub(\"[ýÿ]\", 'y', txt)\n",
        "    txt = re.sub(\"ç\", 'c', txt)\n",
        "    txt = re.sub(\"ğ\", 'g', txt)\n",
        "    txt = re.sub(\"ñ\", 'n', txt)\n",
        "    txt = re.sub(\"ş\", 's', txt)\n",
        "\n",
        "    # Capitals\n",
        "    txt = re.sub(\"[ÀÁÂÃÄÅ]\", 'A', txt)\n",
        "    txt = re.sub(\"[ÈÉÊË]\", 'E', txt)\n",
        "    txt = re.sub(\"[ÌÍÎÏİ]\", 'I', txt)\n",
        "    txt = re.sub(\"[ÒÓÔÕÖ]\", 'O', txt)\n",
        "    txt = re.sub(\"[ÙÚÛÜ]\", 'U', txt)\n",
        "    txt = re.sub(\"[ÝŸ]\", 'Y', txt)\n",
        "    txt = re.sub(\"Ç\", 'C', txt)\n",
        "    txt = re.sub(\"Ğ\", 'G', txt)\n",
        "    txt = re.sub(\"Ñ\", 'N', txt)\n",
        "    txt = re.sub(\"Ş\", 'S', txt)\n",
        "    return txt\n",
        "\n",
        "def remove_titles(txt):\n",
        "    \"\"\"Method to clean special titles that appear as prefixes or suffixes to\n",
        "       people's names (common especially in articles from British/European sources).\n",
        "       The words that are marked as titles are chosen such that they can never appear\n",
        "       in any form as a person's name (e.g., \"Mr\", \"MBE\" or \"Headteacher\").\n",
        "    \"\"\"\n",
        "    honorifics = [\"Dr\", \"Sir\", \"Dame\", \"Professor\", \"Prof\", \"Rev\"]\n",
        "    titles = [\"QC\", \"CBE\", \"MBE\", \"BM\", \"MD\", \"DM\", \"BHB\", \"CBC\", \"Rep\", \"Rep.\",\n",
        "              \"Reverend\", \"Recorder\", \"Headteacher\", \"Councillor\", \"Cllr\", \"Father\", \"Fr\",\n",
        "              \"Mother\", \"Grandmother\", \"Grandfather\", \"Creator\", \"U.S. Rep\", \"Senator\", \"Sen\", \"Rabbi\", \"Imam\"] # could add \"Judge\" but that could also be someone's name\n",
        "    extras = [\"et al\", \"www\", \"href\", \"http\", \"https\", \"Ref\"]\n",
        "    banned_words = r'|'.join(honorifics + titles + extras)\n",
        "    # Ensure only whole words are replaced (\\b is word boundary)\n",
        "    pattern = re.compile(r'\\b({})\\b'.format(banned_words)) \n",
        "    txt = pattern.sub('', txt)\n",
        "    txt = re.sub(\"^\\.\",\"\",txt)\n",
        "    return txt.strip()\n",
        "\n",
        "def lnfn_parse(txt):\n",
        "    \"\"\"Converts names with \"Last, First\" pattern to \"First Last\" pattern.\n",
        "       Works with multiple \"Last, First\" names, returns \"First Last, First Last, ...\"\n",
        "    \"\"\"\n",
        "    lnfn_split = txt.split(\", \")\n",
        "    fnln_split = lnfn_split[::-1]\n",
        "    fnln = \", \".join([\" \".join(x) for x in zip(fnln_split[0::2], fnln_split[1::2])])\n",
        "    return fnln"
      ],
      "metadata": {
        "id": "v9CPe6xnyRHy"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# credit: Lana\n",
        "#looks for phone number and optional leading spaces/punctuation\n",
        "phonenum_regex = '((?: |, |; |\\. |\\| )?\\d{3}[-\\.\\s]??\\d{3}[-\\.\\s]??\\d{4}|\\(\\d{3}\\)\\s*\\d{3}[-\\.\\s]??\\d{4}|\\d{3}[-\\.\\s]??\\d{4}(?: |, |; |\\. |\\| )?)'\n",
        "#looks for email address and optional leading spaces/punctuation\n",
        "email_regex = \"((?: |, |; |\\. |\\| )?[a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\\.[a-zA-Z0-9-.]+(?: |, |; |\\. |\\| )?)\"\n",
        "#looks for title words (case insensitive) and optional leading spaces/punctuation\n",
        "title_regex = '((?: |, |; |\\. |\\| | - )?(?i)(?:Staff Writers?|Editor\\-in\\-Chief|Managing Editor|Political Editor|Editor\\-at\\-large|Columnist|Correspondent|Opinion contributors?|special.*|Capital Bureau)(?: |, |; |\\. |\\| )?)'\n",
        "#capture -, anything after | \n",
        "symbol_regex = ' -|\\|.*$'\n",
        "#capture firstname.lastinitial pattern at end of AJC bylines, \"; .. is . .\" pattern with bios \n",
        "specialpatterns_regex = \"(?: \\w{4,}\\.\\w$)|(?i); .*(?:\\.$| is.*)\"\n",
        "#capture non-name entries including anything after 'from,' and anything containing 'editorial', 'readers', or 'editors' \n",
        "non_name_regex = \".*(?:staff$|staff ).*|Letters to the Editor|from.*|(?i).*editorial.*|(?i).*editors.*|No by-line,|(?i).*readers.*\"\n",
        "#look for news outlets, case insensitive, including optional leading 'the'/connectors/punctuation\n",
        "#For CNN captures anything that comes after\n",
        "outlet_regex = '(?i)(?:, |; | and | for | ?The )?(?i)(?:CNN.*$|Associated Press|New York Times|Washington Times|USA Today|AJC|Green Bay Press-Gazette|Daily Beast|Nation|Houston Chronicle|Sarasota Herald-Tribune|Augusta Chronicle|Arizona Republic|Texas Tribune|Chicago Tribune)'\n",
        "#capture non-comma connectors ('and', ';and', ';', '\\n', '&')\n",
        "connector_regex = '((?i)(?: ;and | and |; *|\\\\n * | & *))'\n",
        "#capture double comma patterns\n",
        "dbl_comma_regex = ', *,+ *'\n",
        "#capture last name, first name pattern\n",
        "# edited to capture names with punctuation (ie. hyphenated names, or names with middle initial)\n",
        "lnfn_regex = \"(^(?:[\\w\\.\\'-])*, (?:[\\w\\.\\'-])*|(?:[\\w\\.\\'-] [\\w\\.])*$)\"\n",
        "#looks for \"The\" preceded and followed by a space, with optional leading comma\n",
        "the_regex = ',? The .*'\n",
        "#looks for \"The\" preceded and followed by a space, with optional leading comma\n",
        "start_the_regex = '^The .*'"
      ],
      "metadata": {
        "id": "vr7jwy1gyiWw"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# credit: Lana\n",
        "rx_patterns = [phonenum_regex,\n",
        "               email_regex,\n",
        "               title_regex, \n",
        "               symbol_regex, \n",
        "               specialpatterns_regex, \n",
        "               outlet_regex, \n",
        "               non_name_regex,\n",
        "               the_regex,\n",
        "               start_the_regex]"
      ],
      "metadata": {
        "id": "e1nisXel0Sve"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# credit: Lana\n",
        "state_list = [\"Alaska\", \"Alabama\", \"Arkansas\", \"American Samoa\", \"Arizona\", \"California\", \"Colorado\", \"Connecticut\", \"District \", \"of Columbia\", \n",
        "              \"Delaware\", \"Florida\", \"Guam\", \"Hawaii\", \"Iowa\", \"Idaho\", \"Illinois\", \"Indiana\", \"Kansas\", \"Kentucky\", \"Louisiana\", \"Massachusetts\", \n",
        "              \"Maryland\", \"Maine\", \"Michigan\", \"Minnesota\", \"Missouri\", \"Mississippi\", \"Montana\", \"North Carolina\", \"North Dakota\", \"Nebraska\", \n",
        "              \"New Hampshire\", \"New Jersey\", \"New Mexico\", \"Nevada\", \"New York\", \"Ohio\", \"Oklahoma\", \"Oregon\", \"Pennsylvania\", \"Puerto Rico\", \n",
        "              \"Rhode Island\", \"South Carolina\", \"South Dakota\", \"Tennessee\", \"Texas\", \"Utah\", \"Virgin Islands\", \"Vermont\", \"Wisconsin\", \n",
        "              \"West Virginia\", \"Wyoming\"]\n",
        "\n",
        "#Patterns of non-name Source Name entries\n",
        "notname_regex = r\"unnamed|editorial|\\bthe\\b|\\bof\\b|opponents|election|vote|liberal |conservatives?| for |documents?|expert|citizens|research|voting|financial|journal|reuters|cnn|bulletin| and |newswire| memo|\\bpoll\\b|spokesperson|[0-9]|\\busa\\b\"\n",
        "org_regex= \"statement|committee|institute|report|groups?|association|university|college|center|coalition|advocate|national|league|associated|american|daily\"\n",
        "govt_regex = \"^gop |federal|u\\.s\\.|supreme court|officials?|administration|department|office|congress|campaign|census|white house|democrat|republican|senate |registrar|secretary|commission|agency|us police|government\"\n",
        "court_regex = \"appeals|circuit|lawyer|attorney|records|\\bcourts?\\b|lawsuit\"\n",
        "long_regex = \"\\S+\\s\\S+\\s\\S+\\s\\S+\\s\\S+\"\n",
        "\n",
        "#Look for strings that do not contain this\n",
        "short_regex = \"\\S+\\s+\\S+\"\n",
        "\n",
        "# regex for one-letter first names\n",
        "one_letter_regex = \"^(\\w\\.)\\W(\\w+)\"\n",
        "\n",
        "notname_regex_list = [notname_regex, org_regex, govt_regex, court_regex, long_regex]"
      ],
      "metadata": {
        "id": "IS_F38yZys8p"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# credit: Lana\n",
        "test_strings = ['Mark', 'By Mark', 'No by-line', 'Opinion by Mark', 'Analysis by Mark']\n",
        "\n",
        "#for test in df.head()['author']:\n",
        "#  print(author_cleaning(test))\n",
        "\n",
        "prefixes = ['letter to the editor by ', 'by ', 'opinion by ', 'analysis by ', 'compiled by ', 'por ']\n",
        "\n",
        "suffixes = [';Editor', ' Florida Times-Union', ' Jacksonville Florida Times-Union', ' Milwaukee Journal Sentinel',\n",
        "            ' Capitol Media Services', ' -- Times Staff Writer', 'Appleton Post-Crescent',  \n",
        "            '; Richmond Times-Dispatch', ' SUN STAFF WRITER', ' News Service Of Florida',\n",
        "            ', Palm Beach Post', '; Editor', '; WPR NEWS', \n",
        "            ' Richmond Times-Dispatch', ' -- Times/Herald Tallahassee Bureau', ', RealClearWire', \n",
        "            '  -- Times Political Editor', '; Austin Bureau', ' Tribune News Service', ' Guest Columnist', \n",
        "            '; LA CROSSE TRIBUNE', ', Omaha World-Herald', ' USA TODAY NETWORK',  \n",
        "            ' InsideSources.com', ' Yuma Sun Editor', ', Capitol Beat News Service', ' South Florida Sun Sentinel',\n",
        "            ' Orlando Sentinel', '; Murphy teaches writing at Virginia Tech', \" Washington Bureau\", '; Contributing Writer', '  -- Times/Herald',  \n",
        "            ' Capitol Beat News Service', ' -- PolitiFact', '; Now News Group', ' Tribune Content Agency', \n",
        "            '; WISCONSIN STATE JOURNAL', '; Washington Bureau Chief', ' The Heritage Foundation',\n",
        "            ', Associated Press; The New York Times contributed.', ', Los Angeles Times', ' Atlanta Journal-Constitution', \n",
        "            ' of Capital News Service', 'Por']"
      ],
      "metadata": {
        "id": "Lf5UcECOzNwR"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# credit: Lana\n",
        "# Drop \"OLD\" labels from name strings\n",
        "df[\"Source Name\"] = df[\"Source Name\"].str.split(\" OLD\", expand =True)[0]\n",
        "df[\"Source Name\"] = df[\"Source Name\"].str.split(r\" \\(OLD\\)\", expand =True)[0]\n",
        "\n",
        "#Remove any names labelled \"Organization\"\n",
        "df['cleaned_name'] = np.where(df['Source Gender'] == \"Organization\", \"not_name\", df['Source Name']) \n",
        "\n",
        "#Fill empty cells\n",
        "df[\"cleaned_name\"] = df[\"Source Name\"].replace(np.nan, \"none\").apply(remove_prefix).apply(remove_suffix).str.title()\n",
        "\n",
        "# replace \" , \" with \", \" to fix some HuffPost author formats\n",
        "df[\"cleaned_name\"] = df[\"cleaned_name\"].replace(\" , \", \", \")\n",
        "\n",
        "# removing stray \"Por\" prefixes\n",
        "df[\"cleaned_name\"] = df[\"cleaned_name\"].replace(\"Por \", \"\")\n",
        "\n",
        "#Remove rx pattern matches\n",
        "df = regex_trim(rx_patterns, column=\"cleaned_name\", df=df)\n",
        "\n",
        "#find non-comma connectors and convert to comma\n",
        "df = regex_trim([connector_regex], \"cleaned_name\", df=df, replace_value=\", \")\n",
        "\n",
        "#after comma conversion, check for multiple commas together and convert to single comma\n",
        "df = regex_trim([dbl_comma_regex], \"cleaned_name\", df=df, replace_value=\", \")\n",
        "\n",
        "#strip trailing commas, and leading and trailing whitespace, then check for trailing commas again\n",
        "df['cleaned_name'] = df['cleaned_name'].str.rstrip(\",\").str.strip().str.rstrip(\",\")\n",
        "\n",
        "#Format names with last name, first name pattern\n",
        "df['cleaned_name'] = np.where(df['cleaned_name'].str.match(lnfn_regex), \n",
        "                                  df['cleaned_name'].apply(lnfn_parse),\n",
        "                                  df['cleaned_name'])\n",
        "\n",
        "#Re-run searches to strip out names starting with 'The'\n",
        "df = regex_trim([the_regex, start_the_regex], \"cleaned_name\", df=df)\n",
        "\n",
        "#Remove accents and titles\n",
        "df['cleaned_name'] = df['cleaned_name'].apply(remove_accents).apply(remove_titles)\n",
        "\n",
        "#Remove non-name regex matches\n",
        "df['cleaned_name'] = np.where(df['cleaned_name'].str.lower().str.contains(\n",
        "    \"|\".join(notname_regex_list), regex=True), \n",
        "    \"not_name\", df['cleaned_name'])\n",
        "\n",
        "#Remove state matches\n",
        "df['cleaned_name'] = np.where(df['cleaned_name'].str.contains(\"|\".join(state_list), regex=True), \n",
        "                                  \"not_name\", df['cleaned_name']) \n",
        "\n",
        "#Remove one word names\n",
        "df['cleaned_name'] = np.where(df['cleaned_name'].str.contains(short_regex, regex=True), \n",
        "                                  df['cleaned_name'], \"not_name\")\n",
        "\n",
        "# remove one letter (abbreviated) first names\n",
        "df['cleaned_name'] = np.where(df['cleaned_name'].str.contains(one_letter_regex, regex=True),\n",
        "                                  \"not_name\", df['cleaned_name'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eOBT0cRyzSUT",
        "outputId": "15b7c9b1-b87a-49aa-8858-2801a10ff422"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Group Labeling"
      ],
      "metadata": {
        "id": "vIW6msuWsx91"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# lookup dictionary which can convert a speaker type to its classification group in constant time\n",
        "source_to_group = {'Foreign Gov/Mil Official': \"Foreign Government\",\n",
        "                   'Media/Journalist': \"External Commentator\",\n",
        "                   'Analyst/Commentator': \"External Commentator\",\n",
        "                   'Citizen': \"External Commentator\",\n",
        "                   'Blogger': \"External Commentator\",\n",
        "                   'Public Polling': \"External Commentator\",\n",
        "                   'Partisans/Fmr. Politicians': \"External Commentator\",\n",
        "                   'Nuke Organization': \"Organization\",\n",
        "                   'International Orgs': \"International\",\n",
        "                   'Non-Profit/NGO': \"Organization\",\n",
        "                   'Think Tanks': \"Organization\",\n",
        "                   'Nuke Organization - Other': \"Organization\",\n",
        "                   'US Rep. & Staff': \"US Congress\",\n",
        "                   'US Senate & Staff': \"US Congress\",\n",
        "                   'Federal Official': \"US Federal Officials\",\n",
        "                   'State/Local Official': \"US Federal Officials\",\n",
        "                   'Judicial Official': \"US Federal Officials\", \n",
        "                   'Former Admin. Officials': \"US Federal Officials\", \n",
        "                   'Regulator': \"International\",\n",
        "                   'US Military': \"US Defense\",\n",
        "                   'Defense Forces': \"US Defense\",\n",
        "                   'Defense': \"US Defense\",\n",
        "                   'US Police': \"US Defense\",\n",
        "                   'Deputy': \"US Defense\",\n",
        "                   'Academic': \"Academic\",\n",
        "                   'Nuke Organization - Academic': \"Organization\",\n",
        "                   'Nuclear Scientist': \"Academic\",\n",
        "                   'Other': \"Other\",\n",
        "                   'Chairman': \"Other\",\n",
        "                   'Terrorist/Extremist': \"Other\",\n",
        "                   'Corporate Official': \"Other\",\n",
        "                   'Information minister': \"Other\",\n",
        "                   'Religious/Clerical': \"Other\",\n",
        "                   'Attorney': \"Other\", \n",
        "                   'Ambassador': \"Other\", \n",
        "                   'Nuclear Official': \"Other\"\n",
        "                  }"
      ],
      "metadata": {
        "id": "7ipVAaa7yNvn"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# credit: Daniel\n",
        "def assign_source_to_group(source_type):\n",
        "  \"\"\"Inputs:\n",
        "     - source_type: str, source type from quote datafame\n",
        "     Outputs:\n",
        "     - str of the bigger speaker category to which source_type belongs\"\"\"\n",
        "  if type(source_type) != str:\n",
        "    return \"Other\"\n",
        "  else:\n",
        "    return source_to_group[source_type]"
      ],
      "metadata": {
        "id": "46ySj7nl73kM"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# credit: Tiffany\n",
        "df[\"speaker_group\"] = df.apply(lambda row: assign_source_to_group(row[\"Source Type\"]),axis=1)"
      ],
      "metadata": {
        "id": "l9ALdzZJx8Gp"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Narrowing the quotes dataframe down to just records where the source was an \n",
        "# actual name, not a non_name\n",
        "df = df[df[\"cleaned_name\"] != \"not_name\"]"
      ],
      "metadata": {
        "id": "uRC2eBbeyPpm"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Context Extraction Functions"
      ],
      "metadata": {
        "id": "lCPEdrVLs5YV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# credit: Daniel\n",
        "# helper function to extract full article text, useful for debugging cases where the context extraction function fails\n",
        "def content_of(art_id):\n",
        "  \"\"\"Inputs:\n",
        "     - art_id: id of the article to get the full text of\n",
        "     Outputs:\n",
        "     - str: the full article content as a string\"\"\"\n",
        "  just_id = arts[arts[\"Article ID\"] == art_id][\"Content\"]\n",
        "  if len(just_id) > 0:\n",
        "    return arts[arts[\"Article ID\"] == art_id][\"Content\"].iloc[0]\n",
        "  else: \n",
        "    return \"\"\n",
        "  #return arts[arts[\"Article ID\"] == art_id][\"Content\"].iloc[0].replace(\"\\\"\",\"'\")"
      ],
      "metadata": {
        "id": "NaRuoqBgKMtA"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# credit: Tiffany\n",
        "def find_sentence(df, article_id, name, sentence_num=0):\n",
        "    try:\n",
        "        text = df[df['Article ID'] == article_id]['Content'].iloc[0]\n",
        "    except:\n",
        "        #print(\"Article ID not found in dataset.\")\n",
        "        return \"\"\n",
        "    text = text.lower()\n",
        "    name = name.lower()\n",
        "    # convert \" to ' and ´ to ' to account for fancy names\n",
        "    text = text.replace(\"\\\"\",\"'\")\n",
        "    text = text.replace(\"-\",\" \")\n",
        "    name = name.replace(\"´\",\"'\")\n",
        "    name = name.replace(\"-\", \" \")\n",
        "    try:\n",
        "        sentence = [s+ '.' for s in text.split('.') if name in s][sentence_num]\n",
        "        return sentence\n",
        "    except:\n",
        "        #print(\"Sentence not found for \" + name)\n",
        "        return \"\"\n",
        "\n",
        "def extract_comma_addendum_context(df, article_id, name, sentence_num=0):\n",
        "    if type(name) != str:\n",
        "      name = \"\"\n",
        "    name = name.lower()\n",
        "    content = content_of(article_id)\n",
        "    content = content.lower()\n",
        "    #only get info from <name>, <speaker info>, ...\n",
        "    try:\n",
        "        search_obj = re.search(name+',(\\W+(?:\\w+\\W+){0,12})', content) #re.search(r',(?<=,)[^,]+(?=,)')\n",
        "        return search_obj.group(1)#.group() #turns object into string\n",
        "    except:\n",
        "        return \"\""
      ],
      "metadata": {
        "id": "lxSOEHem8KyD"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# credit: Daniel Chung\n",
        "# Helper function to find the context surrounding the first time a given\n",
        "# speaker was mentioned in an article, with the purpose being to isolate\n",
        "# the text most critical to classifying the speaker type\n",
        "def find_first_context(art_ID, name, range=12):\n",
        "  \"\"\"Inputs:\n",
        "     - art_ID: int, the ID of the article to be searched for context\n",
        "     - name: str, the name of the quote speaker\n",
        "     - range: int, how many words both before and after the first mention of the \n",
        "              speaker we wish to see\n",
        "     Outputs:\n",
        "     - str: <range> words before the first mention of the speaker, and <range> \n",
        "            words after the first mention of the speaker. Conceptually we are\n",
        "            returning the context surrounding the first time <name> was\n",
        "            mentioned in article <art_ID>\"\"\"\n",
        "  # get the full text of the article\n",
        "  text = \"\"\n",
        "  just_id = arts[arts['Article ID'] == art_ID]\n",
        "  if len(just_id) > 0:\n",
        "    text = just_id['Content'].iloc[0]\n",
        "  # convert to lower caps\n",
        "  text = text.lower()\n",
        "  name = name.lower()\n",
        "  # convert \" to ' and ´ to ' to account for fancy names\n",
        "  text = text.replace(\"\\\"\",\"'\")\n",
        "  text = text.replace(\"-\",\" \")\n",
        "  name = name.replace(\"´\",\"'\")\n",
        "  name = name.replace(\"-\", \" \")\n",
        "  # split the full text into a list of paragraphs\n",
        "  paragraphs =  re.split(r\"\\n\\n\", text)\n",
        "  # find the paragraph where the name is first mentioned\n",
        "  first_mention = \"\"\n",
        "  #last_name = name.split()[-1]\n",
        "  for paragraph in paragraphs:\n",
        "    if name in paragraph:\n",
        "      first_mention = paragraph\n",
        "      break\n",
        "  # return the context (surrounding words before and after) using regex\n",
        "  context_pattern = '(\\W+(?:\\w+\\W+){0,'+str(range)+'}' + name + '\\W+(?:\\w+\\W+){0,'+str(range)+'})'\n",
        "  matches = re.search(context_pattern, first_mention)\n",
        "  if matches:\n",
        "    context = re.search(context_pattern, first_mention)[0]\n",
        "  else:\n",
        "    context = \"\"\n",
        "  return context"
      ],
      "metadata": {
        "id": "6N80yGyNsp7e"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# credit: Tiffany\n",
        "# added benefit of directly classifying self-explanatory names (no need to pre-screen)\n",
        "# also should account for common abbrevations like 'sen.','rep.'\n",
        "def classifyFromPrefix(name, text): \n",
        "    \"\"\"Classifies name if the three words preceding it matches a known label like 'President','General', 'Professor', etc.\"\"\"    \n",
        "    try: \n",
        "        prefix = re.search(r'((?:\\S+\\s+){0,3}\\b)' + name.lower(), text.lower()).group(0)\n",
        "    except:\n",
        "        return \"\"\n",
        "    else:\n",
        "        if any(word in prefix for word in ['former','foreign','media','news','chinese','iran','south korea']):\n",
        "            return \"External Commentator\"\n",
        "        if any(word in prefix for word in ['justice','governor','president']):\n",
        "            return \"US Federal Officials\"\n",
        "        if any(word in prefix for word in ['senator','representative','sen.','rep.','house','democrat','republican']):\n",
        "            return \"US Congress\"\n",
        "        us_defense = ['admiral','adm.','general','gen.','major','maj.','captain','capt.','lieutenant','lm.',\n",
        "                      'colonel','col.','military','commander','cmdr.','air force','marine']\n",
        "        if any(word in prefix for word in us_defense):\n",
        "            return \"US Defense\"\n",
        "        if any(word in prefix for word in ['professor','scholar','university']):\n",
        "            return \"Academic\"\n",
        "        if any(word in prefix for word in ['pastor','rev.','reverend','minister','bishop','pope']):\n",
        "            return \"Other\" #religious\n",
        "        return \"\""
      ],
      "metadata": {
        "id": "XvK9w06Er7rx"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Latest Context Extraction Function: TIffany's pipeline method"
      ],
      "metadata": {
        "id": "6SIQFzVJv6DK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First search for pattern \"name is ___\", if no match then search for \"name who is _____ \", if no match then search for \"name, ______ ,\", and if nothing matches then take the words preceding and following the first mention of the name."
      ],
      "metadata": {
        "id": "ddKnwC2hwBOu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# credit: Tiffany\n",
        "def getContext(df, article_id, name, noPattern=False):\n",
        "    #sentence = find_sentence(df, article_id, name)\n",
        "    #if sentence == \"\": #can't find sentence\n",
        "    #    return sentence\n",
        "    content = content_of(article_id)\n",
        "    content = content.lower()\n",
        "    \n",
        "    name = name.lower()\n",
        "    name = name.replace(\"´\",\"'\")\n",
        "    name = name.replace(\"-\", \" \")\n",
        "    \n",
        "    # pattern match <name> is ______ (,.:;\\-!?\"()\n",
        "    match = re.search(name + r'is [^,.:;\\-!?\"(]+', content) \n",
        "    if match is None:\n",
        "        # pattern match <name> who is _____(,.)\n",
        "        match = re.search(name + r'who is [^,.:;\\-!?\"(]+', content)\n",
        "    if match is None:\n",
        "        # pattern match <name>, _____ , ... MAKE SURE NO QUOTES\n",
        "        match = re.search(name + r',((?<=,)[^,\"]+(?=,))', content)\n",
        "    if match is None:\n",
        "        # pattern match <name>, _____ . \n",
        "        match = re.search(name + r',(\\W+(?:\\w+\\W+)).', content)   #(\\W+(?:\\w+\\W+) any text before name\n",
        "    if match is None and noPattern == True:\n",
        "        #simple get the words around name in text\n",
        "        return find_first_context(name, article_id, range=12)\n",
        "    try:\n",
        "        return match.group(1)\n",
        "    except:\n",
        "        return \"\""
      ],
      "metadata": {
        "id": "IAcwVVKLr_5o"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Taking a random sample of quotes to keep computations managable my memory standards\n",
        "df_sample = df.sample(n=20000)"
      ],
      "metadata": {
        "id": "ItAuMLTE_AAL"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a column of context for each name for the quote in that record\n",
        "df_sample['Context'] = df_sample.apply(lambda x: getContext(df_sample, x['Article ID'], x['Source Name']), axis=1)"
      ],
      "metadata": {
        "id": "hDgfQEmE-_Pq"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature brainstorming"
      ],
      "metadata": {
        "id": "LrUit3-ZwfPS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Using TF-IDF scores to get feature ideas. Will be comparing the context extracted from speakers in each speaker category."
      ],
      "metadata": {
        "id": "A_AUNWhWwhdG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Credit: https://github.com/dlab-berkeley/Python-Text-Analysis-Fundamentals/blob/main/day-2/02-unsupervised-solutions.ipynb\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "tfidfvec = TfidfVectorizer()\n",
        "sparse_tfidf = tfidfvec.fit_transform(df_sample['Context'])"
      ],
      "metadata": {
        "id": "S1iNow898LoL"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Credit: https://github.com/dlab-berkeley/Python-Text-Analysis-Fundamentals/blob/main/day-2/02-unsupervised-solutions.ipynb\n",
        "tfidf = pd.DataFrame(sparse_tfidf.toarray(), columns=tfidfvec.get_feature_names())\n",
        "tfidf['speaker_group'] = df_sample[\"speaker_group\"]\n",
        "tfidf.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 291
        },
        "id": "ruw1Ghx-8QCl",
        "outputId": "f431a86d-085b-497a-ae3a-2fb29b6654cc"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    00  000   01   02   03   04   05   06   07   08  ...  zealand  zecurion  \\\n",
              "0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...      0.0       0.0   \n",
              "1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...      0.0       0.0   \n",
              "2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...      0.0       0.0   \n",
              "3  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...      0.0       0.0   \n",
              "4  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...      0.0       0.0   \n",
              "\n",
              "   zero  zheng  zinke  zionist  zone  zuckerman  zug       speaker_group  \n",
              "0   0.0    0.0    0.0      0.0   0.0        0.0  0.0                 NaN  \n",
              "1   0.0    0.0    0.0      0.0   0.0        0.0  0.0                 NaN  \n",
              "2   0.0    0.0    0.0      0.0   0.0        0.0  0.0                 NaN  \n",
              "3   0.0    0.0    0.0      0.0   0.0        0.0  0.0  Foreign Government  \n",
              "4   0.0    0.0    0.0      0.0   0.0        0.0  0.0                 NaN  \n",
              "\n",
              "[5 rows x 5894 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-bfd2e12f-63d0-4e94-97be-b1cae7ee0e41\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>00</th>\n",
              "      <th>000</th>\n",
              "      <th>01</th>\n",
              "      <th>02</th>\n",
              "      <th>03</th>\n",
              "      <th>04</th>\n",
              "      <th>05</th>\n",
              "      <th>06</th>\n",
              "      <th>07</th>\n",
              "      <th>08</th>\n",
              "      <th>...</th>\n",
              "      <th>zealand</th>\n",
              "      <th>zecurion</th>\n",
              "      <th>zero</th>\n",
              "      <th>zheng</th>\n",
              "      <th>zinke</th>\n",
              "      <th>zionist</th>\n",
              "      <th>zone</th>\n",
              "      <th>zuckerman</th>\n",
              "      <th>zug</th>\n",
              "      <th>speaker_group</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Foreign Government</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 5894 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bfd2e12f-63d0-4e94-97be-b1cae7ee0e41')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-bfd2e12f-63d0-4e94-97be-b1cae7ee0e41 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-bfd2e12f-63d0-4e94-97be-b1cae7ee0e41');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Supposed best features within quote context that distinguish foreign government sources\n",
        "foreign_gov = tfidf[tfidf['speaker_group']==\"Foreign Government\"]\n",
        "tfi_ranked = foreign_gov.max(numeric_only=True).sort_values(ascending=False)\n",
        "tfi_ranked.head(30)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jUAZT5ty8da_",
        "outputId": "729723fa-6c74-4864-a1da-8b03bc12da11"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "the          1.000000\n",
              "in           1.000000\n",
              "north        1.000000\n",
              "testified    1.000000\n",
              "said         1.000000\n",
              "left         1.000000\n",
              "calif        1.000000\n",
              "according    1.000000\n",
              "mo           1.000000\n",
              "iran         1.000000\n",
              "stoddard     1.000000\n",
              "director     1.000000\n",
              "an           1.000000\n",
              "illinois     0.820028\n",
              "monica       0.784528\n",
              "acosta       0.742304\n",
              "lashed       0.728848\n",
              "henry        0.725427\n",
              "mossad       0.718491\n",
              "gloria       0.712842\n",
              "blitzer      0.708914\n",
              "karadsheh    0.707107\n",
              "jomana       0.707107\n",
              "wolf         0.705295\n",
              "borger       0.701325\n",
              "book         0.697112\n",
              "even         0.695537\n",
              "ed           0.688299\n",
              "nato         0.687388\n",
              "supreme      0.677096\n",
              "dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Supposed best features within quote context that distinguish external commentator sources\n",
        "external_commentator = tfidf[tfidf['speaker_group']==\"External Commentator\"]\n",
        "tfi_ranked = external_commentator.max(numeric_only=True).sort_values(ascending=False)\n",
        "tfi_ranked.head(30)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GY0VDZ9_8hPV",
        "outputId": "29af5115-8b28-4681-b7c8-cd0d646360a7"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "trump        1.000000\n",
              "72           1.000000\n",
              "insisted     1.000000\n",
              "said         1.000000\n",
              "president    1.000000\n",
              "the          1.000000\n",
              "wash         1.000000\n",
              "east         1.000000\n",
              "came         1.000000\n",
              "ohio         1.000000\n",
              "fox          1.000000\n",
              "example      0.915210\n",
              "bolton       0.786207\n",
              "frum         0.785599\n",
              "fudan        0.780660\n",
              "cia          0.749074\n",
              "cabinet      0.720577\n",
              "bash         0.712247\n",
              "reza         0.710256\n",
              "jill         0.707107\n",
              "dougherty    0.707107\n",
              "kyung        0.707107\n",
              "kate         0.707107\n",
              "lah          0.707107\n",
              "bolduan      0.707107\n",
              "sayah        0.703944\n",
              "dana         0.701929\n",
              "iaea         0.623445\n",
              "david        0.618736\n",
              "john         0.617963\n",
              "dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Supposed best features within quote context that distinguish organization sources\n",
        "organization = tfidf[tfidf['speaker_group']==\"Organization\"]\n",
        "tfi_ranked = organization.max(numeric_only=True).sort_values(ascending=False)\n",
        "tfi_ranked.head(30)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XW6rOAch8k5d",
        "outputId": "8b64806a-d945-4929-eb84-843163bb8337"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "the               1.000000\n",
              "fox               1.000000\n",
              "washington        1.000000\n",
              "was               1.000000\n",
              "calif             1.000000\n",
              "this              1.000000\n",
              "now               1.000000\n",
              "belgium           0.934991\n",
              "king              0.774024\n",
              "kurtz             0.746106\n",
              "palin             0.707107\n",
              "sarah             0.707107\n",
              "functioning       0.669931\n",
              "howard            0.665827\n",
              "john              0.633157\n",
              "superintendent    0.552270\n",
              "keynote           0.544787\n",
              "carrier           0.542017\n",
              "country           0.534437\n",
              "russian           0.529527\n",
              "integrated        0.512213\n",
              "raytheon          0.507343\n",
              "systems           0.478164\n",
              "minister          0.467742\n",
              "later             0.458913\n",
              "deputy            0.457597\n",
              "speaker           0.444915\n",
              "added             0.444915\n",
              "charge            0.437144\n",
              "strike            0.431876\n",
              "dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Supposed best features within quote context that distinguish US congress sources\n",
        "us_congress = tfidf[tfidf['speaker_group']==\"US Congress\"]\n",
        "tfi_ranked = us_congress.max(numeric_only=True).sort_values(ascending=False)\n",
        "tfi_ranked.head(30)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HxWrC_QdGw6D",
        "outputId": "40a6304e-ecbd-4bcc-917d-291a913c856c"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "senior            1.000000\n",
              "minn              1.000000\n",
              "accused           1.000000\n",
              "former            1.000000\n",
              "though            1.000000\n",
              "meanwhile         1.000000\n",
              "kan               1.000000\n",
              "said              1.000000\n",
              "however           1.000000\n",
              "legal             1.000000\n",
              "israel            1.000000\n",
              "weapons           0.791250\n",
              "blitzer           0.708914\n",
              "starr             0.708747\n",
              "barbara           0.705462\n",
              "wolf              0.705295\n",
              "thanks            0.645914\n",
              "ambassador        0.642264\n",
              "the               0.630978\n",
              "iaea              0.623445\n",
              "nuclear           0.611492\n",
              "twice             0.576314\n",
              "economics         0.553268\n",
              "administration    0.549258\n",
              "phone             0.542240\n",
              "unification       0.539544\n",
              "via               0.506169\n",
              "usa               0.505767\n",
              "strong            0.474918\n",
              "met               0.467820\n",
              "dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Supposed best features within quote context that distinguish US federal official sources\n",
        "us_fed_officials = tfidf[tfidf['speaker_group']==\"US Federal Officials\"]\n",
        "tfi_ranked = us_fed_officials.max(numeric_only=True).sort_values(ascending=False)\n",
        "tfi_ranked.head(30)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s3zXtEycGzTT",
        "outputId": "6deada8f-5734-43ee-d808-556ddee9f2d9"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "director     1.000000\n",
              "said         1.000000\n",
              "ala          1.000000\n",
              "told         1.000000\n",
              "author       1.000000\n",
              "the          1.000000\n",
              "texas        1.000000\n",
              "fox          1.000000\n",
              "former       1.000000\n",
              "who          1.000000\n",
              "74           1.000000\n",
              "fla          1.000000\n",
              "ph           1.000000\n",
              "56           1.000000\n",
              "co           1.000000\n",
              "european     1.000000\n",
              "calif        1.000000\n",
              "arkansas     0.824032\n",
              "mattingly    0.785599\n",
              "cardenas     0.760928\n",
              "baer         0.752146\n",
              "turkey       0.734195\n",
              "candy        0.729244\n",
              "henry        0.725427\n",
              "anderson     0.719979\n",
              "gloria       0.712842\n",
              "reza         0.710256\n",
              "starr        0.708747\n",
              "brian        0.708747\n",
              "dougherty    0.707107\n",
              "dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Supposed best features within quote context that distinguish US defense sources\n",
        "us_defense = tfidf[tfidf['speaker_group']==\"US Defense\"]\n",
        "tfi_ranked = us_defense.max(numeric_only=True).sort_values(ascending=False)\n",
        "tfi_ranked.head(30)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uS3Z7I05G1Zs",
        "outputId": "a6aecf53-2e74-41a7-f7b2-b79bd47bc0a7"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "43              1.000000\n",
              "mcconnell       0.738287\n",
              "elam            0.707107\n",
              "stephanie       0.707107\n",
              "spokesperson    0.674487\n",
              "publisher       0.534350\n",
              "concerned       0.531514\n",
              "appearances     0.523369\n",
              "white           0.500238\n",
              "staff           0.500238\n",
              "scientists      0.497631\n",
              "series          0.487839\n",
              "magazine        0.479414\n",
              "friday          0.472168\n",
              "union           0.467852\n",
              "office          0.467439\n",
              "throughout      0.467056\n",
              "of              0.458522\n",
              "house           0.456159\n",
              "38              0.449838\n",
              "nation          0.441818\n",
              "stimson         0.436159\n",
              "chief           0.422060\n",
              "pentagon        0.421528\n",
              "day             0.410743\n",
              "editor          0.408024\n",
              "times           0.374420\n",
              "his             0.366757\n",
              "fellow          0.340687\n",
              "washington      0.306564\n",
              "dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Supposed best features within quote context that distinguish academic sources\n",
        "academic = tfidf[tfidf['speaker_group']==\"Academic\"]\n",
        "tfi_ranked = academic.max(numeric_only=True).sort_values(ascending=False)\n",
        "tfi_ranked.head(30)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PVnfDHZkG3bt",
        "outputId": "188f110b-b688-4a0e-a8d1-cac69942e19c"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "who           1.000000\n",
              "an            1.000000\n",
              "said          1.000000\n",
              "large         0.727603\n",
              "editor        0.593099\n",
              "nations       0.550154\n",
              "rachel        0.544085\n",
              "engel         0.528122\n",
              "integrated    0.512213\n",
              "raytheon      0.507343\n",
              "ukraine       0.499142\n",
              "systems       0.478164\n",
              "ambassador    0.467275\n",
              "maddow        0.467159\n",
              "richard       0.454776\n",
              "visit         0.448662\n",
              "united        0.441601\n",
              "back          0.440264\n",
              "just          0.424868\n",
              "that          0.424056\n",
              "former        0.362016\n",
              "at            0.344713\n",
              "honeymoon     0.341104\n",
              "trial         0.341104\n",
              "from          0.338472\n",
              "defense       0.332534\n",
              "murder        0.327558\n",
              "contain       0.327558\n",
              "judge         0.317947\n",
              "to            0.316596\n",
              "dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Supposed best features within quote context that distinguish other sources\n",
        "other = tfidf[tfidf['speaker_group']==\"Other\"]\n",
        "tfi_ranked = other.max(numeric_only=True).sort_values(ascending=False)\n",
        "tfi_ranked.head(30)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qpp87F-vG6g8",
        "outputId": "47b59f88-eb45-487b-b65b-f43a5cc8e3bf"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ashton        0.457302\n",
              "syria         0.448090\n",
              "ben           0.427338\n",
              "wedeman       0.427338\n",
              "sesay         0.408322\n",
              "isha          0.408322\n",
              "scholar       0.403268\n",
              "drew          0.394830\n",
              "griffin       0.381338\n",
              "middle        0.360059\n",
              "ambassador    0.335831\n",
              "east          0.334385\n",
              "institute     0.297764\n",
              "attacks       0.290056\n",
              "austrian      0.287127\n",
              "included      0.275725\n",
              "former        0.260182\n",
              "since         0.254482\n",
              "capital       0.248143\n",
              "catherine     0.232406\n",
              "hour          0.230466\n",
              "to            0.227539\n",
              "european      0.227046\n",
              "six           0.217249\n",
              "and           0.216809\n",
              "wednesday     0.209159\n",
              "meeting       0.202189\n",
              "union         0.198349\n",
              "the           0.197043\n",
              "between       0.196052\n",
              "dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Supposed best features within quote context that distinguish international sources\n",
        "international = tfidf[tfidf['speaker_group']==\"International\"]\n",
        "tfi_ranked = international.max(numeric_only=True).sort_values(ascending=False)\n",
        "tfi_ranked.head(30)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rOOZIdYDG9Ji",
        "outputId": "a901a414-e46c-408d-bf5a-e99aa15d85b8"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "vice          1.000000\n",
              "illinois      0.780742\n",
              "republican    0.544904\n",
              "watching      0.538237\n",
              "cnfi          0.501157\n",
              "richard       0.463487\n",
              "going         0.434598\n",
              "clinton       0.393311\n",
              "aide          0.390657\n",
              "what          0.387987\n",
              "100th         0.381500\n",
              "white         0.335880\n",
              "has           0.320680\n",
              "spokesman     0.317120\n",
              "house         0.306283\n",
              "of            0.305814\n",
              "is            0.294635\n",
              "on            0.263177\n",
              "former        0.235537\n",
              "for           0.200862\n",
              "and           0.196273\n",
              "brigade       0.190750\n",
              "crews         0.190750\n",
              "keeping       0.190750\n",
              "biggest       0.183175\n",
              "ready         0.177801\n",
              "colorado      0.177801\n",
              "overseas      0.177801\n",
              "jump          0.177801\n",
              "healthy       0.177801\n",
              "dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "NYB__nc8G-od"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
